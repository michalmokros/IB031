{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Tutorial 02 â€“ Exploration Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Exploration data analysis or initial data analysis is a task of assessing and understanding the data. One can describe the data using statistics (e.g., mean, standard deviation, and quantiles), distributions (e.g., normal, exponential, and log-normal), and plots (e.g. histograms, box plots, and scatter plots). All of these techniques are aimed at providing simple and comprehensive image of what actually is in the data, how noisy is the data, and what model assumptions might by violated by this data. We do not have any model right now, so we will focus more on data understanding and quality assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's use `Pandas` to load some data and explore it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasaurus = pd.read_csv(\n",
    "    \"https://www.fi.muni.cz/~xcechak1/IB031/datasets/datasaurus.csv\",\n",
    "    header=0,  # do not use values as column names\n",
    "    names=[\"x\", \"y\"],  # set custom column names\n",
    ")\n",
    "datasaurus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The dataset is fairly small, only 141 observations and 2 features per observation. We can now calculate basic statistics of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasaurus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Both features live roughly between 0 and 100. Feature `x` seems to be shifted slightly towards 100. We can also calculate correlation of the two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasaurus.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "So far, the features seems to be pretty random and not much correlated. But you should never trust the summary statistics alone, you should always plot your data. Here is why..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasaurus.plot(kind=\"scatter\", x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Images are very natural way of representation for humans and we are well adapted at seeing patterns (even in data in which there are no patterns). However, choosing the right kind of plot (and its parameters) is a bit tricky. Here are a few other plots that do not convey that much data comprehension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Line plot\n",
    "Each feature is represented by a curve that follows changes in its value. This plot is most useful for time series data or data with some other natural progression. Sorting values might help in some cases, but not in this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasaurus.plot(kind=\"line\")\n",
    "# sort data by value of `y` and reindex the data\n",
    "datasaurus.sort_values(by=[\"y\"]).reset_index(drop=True).plot(kind=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Histograms\n",
    "Histograms are especially useful for getting an idea of the feature distribution. It can take years of experience to recognize distributions from mean, deviation and quantiles, but it takes seconds to do that with histograms. Histograms have one important parameter: number of bins. Having few bins smooths data too much and having too many bins dilutes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasaurus.hist()\n",
    "datasaurus.hist(bins=3)\n",
    "datasaurus.hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Box plot\n",
    "Box plots are classical way of representing distributions. The upper and lower side of the 'box' are 25 and 75 quantiles. The line inside the box is 50 quantile (median). The 'whiskers' are typically the last data point inside 1.5 times the inter quantile range (IQR). The dots below and above 'whiskers' are often labeled as outliers, an unlikely observations given the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasaurus.plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Robomission dataset\n",
    "For basic description of structure see the [GitHub page](https://github.com/adaptive-learning/adaptive-learning-research/tree/master/data/robomission-2019-12)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts = pd.read_csv(\n",
    "    \"https://www.fi.muni.cz/~xcechak1/IB031/datasets/attempts.csv\", parse_dates=[3]\n",
    ")\n",
    "attempts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's see how well the students are doing, i.e., what are their solving times, on the first problem in the system (problem id 51)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts[attempts.problem == 51].time.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "That is weird, right. Seems like it takes everybody the same amount of time to solve the problem. Well, not really."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 1</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Select only a subset of rows selected in the previous example and draw more representative histogram of solving times similar to [this](https://www.fi.muni.cz/~xcechak1/IB031/tutorial02/img/problem51.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts[(attempts.problem == 51) & (attempts.time < 60 * 2)].time.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "From the histogram and from published papers it seems like the solving time follows log-normal distribution, i.e., logarithm of solving time is normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 2</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "1. Create a new column with natural logarithm of values in column `time`.\n",
    "2. Test the hypothesis that natural logarithm of solving time for **problem 6** of students that have actually **solved** the problem is normally distributed. Use function `normaltest` from `scipy` to do the test. Expected result of the test is p-value of 3.628811540066463e-151.\n",
    "3. Based on the p-value of the test (and the example in `scipy` documentation for `normaltest` function) decide whether we can reject the hypothesis that the log times are distributed normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import normaltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts[\"log_time\"] = np.log(attempts[\"time\"])\n",
    "normaltest(attempts[(attempts.problem == 6) & (attempts.solved)].log_time)\n",
    "# The p-value of the test quite small so we can reject the hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To have statistically reliable results from these tests or any kind of analysis we have to have enough data. Let's check we do have enough data collected for each of the problems in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 3</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Compute number of occurrences of each problem in the data and plot the distribution using bar plot. Make sure to order problems from most common to least common for better readability of the plot. The resulting plot should look like [this](https://www.fi.muni.cz/~xcechak1/IB031/tutorial02/img/problem_counts.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts.problem.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is not really visually pleasing nor informative. There is no title (What does the plot show?), axes are missing labels (What kind of numbers are on y-axis?), and tick labels (What is the third number from the left on the bottom x-axis?).\n",
    "\n",
    "All of these parameters can be changed using `matplotlib`'s `axis` object. All of the plots were actually drawn by `matplotlib` but pandas luckily provides high-level API, so you don't have to draw individual lines. Let's pimp the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = (\n",
    "    pd.Series(np.random.randint(0, 8000, 84))\n",
    "    .sort_values(ascending=False)\n",
    "    .plot(kind=\"bar\", figsize=(15, 5))\n",
    ")  # random data similar to previous exercise\n",
    "ax.set_title(\"Number of attempts per problem\")  # plot title\n",
    "ax.set_ylabel(\"Number of attempts\")  # y-axis (vertical) label\n",
    "ax.set_xlabel(\"Problem id\")  # x-axis (horizontal) label\n",
    "ax.tick_params(\n",
    "    axis=\"x\", rotation=0, labelsize=8\n",
    ")  # make number smaller and stand upright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 4</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the axis modification example above to improve plot from Exercise 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = attempts.problem.value_counts().plot(kind=\"bar\", figsize=(15, 5))\n",
    "ax.set_title(\"Number of attempts per problem\")\n",
    "ax.set_ylabel(\"Number of attempts\")\n",
    "ax.set_xlabel(\"Problem id\")\n",
    "ax.tick_params(axis=\"x\", rotation=0, labelsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! Now this plot might be somewhat useful. You can also save the plot for later. You need to import `pyplot` and call `savefig` function. It will save everything that has been plotted in the cells so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# just plot it again\n",
    "ax = (\n",
    "    pd.Series(np.random.randint(0, 8000, 84))\n",
    "    .sort_values(ascending=False)\n",
    "    .plot(kind=\"bar\", figsize=(15, 5))\n",
    ")  # random data similar to previous exercise\n",
    "ax.set_title(\"Number of attempts per problem\")  # plot title\n",
    "ax.set_ylabel(\"Number of attempts\")  # y-axis (vertical) label\n",
    "ax.set_xlabel(\"Problem id\")  # x-axis (horizontal) label\n",
    "ax.tick_params(\n",
    "    axis=\"x\", rotation=0, labelsize=8\n",
    ")  # make number smaller and stand upright\n",
    "\n",
    "# the file format is automatically recognised from file extension\n",
    "plt.savefig(\n",
    "    \"my_plot.png\",  # file name of the save image\n",
    "    dpi=300,  # resolution of produced image\n",
    "    bbox_inches=\"tight\",  # make borders tigther to plot\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is a huge library and while it can do a lot of things, it's far from intuitive and easy. Luckily, there are higher-level plotting libraries like `seaborn` or `plotly`. We will focus on `seaborn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  # import seaborn\n",
    "\n",
    "sns.set()  # make plots magically prettier :)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=attempts,  # dataframe to take values from\n",
    "    x=\"n_edits\",  # column name to use as x-axis\n",
    "    y=\"n_executions\",  # column name to use as y-axis\n",
    "    hue=\"problemset\",  # column name whos value will decide point color\n",
    "    palette=\"viridis\",  # collor palet to use\n",
    "    alpha=0.5,  # make point a bit translucent to better see the density of points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from making plots nicer, it also comes with handy plotting functions both for plots introduced earlier and also other plots not supported by `Pandas`'s `plot` method. \n",
    "\n",
    "First function is `pairplot` that lets you plot all columns from a data frame against each other using scatter plots and plot each column histogram - all in one grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"https://www.fi.muni.cz/~xcechak1/IB031/datasets/weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(weather, vars=[\"temperature\", \"humidity\", \"windy\"], hue=\"play\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 5</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `pairplot` to plot columns **time**, **n_edits**, and **n_executions** from attempts dataset and change hue based on whether students **solved** the **problem 17**. The result should look like [this](https://www.fi.muni.cz/~xcechak1/IB031/tutorial02/img/attempts_pairplot.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    attempts[attempts.problem == 17],  # plot data about problem 17\n",
    "    vars=[\"time\", \"n_edits\", \"n_executions\"],  # what columns to plot against each other\n",
    "    hue=\"solved\",  # change color based on student ability to solve problem\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at heatmaps, another plot not available in `Pandas`.\n",
    "\n",
    "#### Heatmap\n",
    "Heatmaps are used to visualize function values either in plane or on a discrete grid. The color is based on the function value. Humans can easily see \"hot spots\" in the data where the function value is different.\n",
    "\n",
    "As an example, let's plot number of transported passengers through months and years. The plot illustrates the peak in summer months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = sns.load_dataset(\"flights\")\n",
    "flights = flights.pivot(\"month\", \"year\", \"passengers\")\n",
    "ax = sns.heatmap(flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When collecting data, we are often interested in patterns in time. There are two typical goals of exploratory data analysis for time-series data. \n",
    "1. We are interested in seeing patterns in progression of some variable in time that will help us in forecasting future values (e.g., stock markets, weather, and machine failures).\n",
    "2. We are interested in differences in data collected at different points in time and whether they share the same characteristics (e.g., Is the traffic data similar in the morning and in the evening?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Exercise 6</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the stock markets! We want to visualize stock prices throughout year 2017 and find out if we could see any trends. Then, we want to compare how Google stock prices evolved in each month. Finally, we want to explore if there are any patterns in stock price daily changes on different days of the week.\n",
    "\n",
    "1. Load dataset with [sample of real stocks data](https://www.fi.muni.cz/~xcechak1/IB031/datasets/stocks_sample.csv).\n",
    "2. Make sure that column date has been converted to type `datetime` and is not interpreted as string!\n",
    "3. Create three new columns called `weekday`, `month`, and `day` with number of week day, number of month, and day number respectively. See `Pandas` [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetimelike-properties) on how to extract these informations from date column.\n",
    "4. Use `seaborns`'s `lineplot` to plot stock prices throughout 2017 at market closing. The plot should look like [this](https://www.fi.muni.cz/~xcechak1/IB031/tutorial02/img/stocks_year.png).\n",
    "5. Use the same function to plot Google's stocks (stocks with name 'GOOGL') progression in each of the months. The plot should look like [this](https://www.fi.muni.cz/~xcechak1/IB031/tutorial02/img/google_stocks.png).\n",
    "6. Create new column with differences in opening and closing stock prices.\n",
    "7. Visualize the differences for each weekday using `Seaborn`'s `boxplot` function. The plot should look like [this](https://www.fi.muni.cz/~xcechak1/IB031/tutorial02/img/stocks_weekday.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "stocks = pd.read_csv(\"../datasets/stocks_sample.csv\", parse_dates=[0])\n",
    "# 3\n",
    "stocks[\"weekday\"] = stocks.date.dt.weekday\n",
    "stocks[\"month\"] = stocks.date.dt.month\n",
    "stocks[\"day\"] = stocks.date.dt.day\n",
    "# 4\n",
    "sns.lineplot(data=stocks, x=\"date\", y=\"close\", hue=\"name\")\n",
    "plt.show()\n",
    "# 5\n",
    "sns.lineplot(data=stocks[stocks.name == \"GOOGL\"], x=\"day\", y=\"close\", hue=\"month\")\n",
    "plt.show()\n",
    "# 6\n",
    "stocks[\"difference\"] = stocks[\"close\"] - stocks[\"open\"]\n",
    "plt.show()\n",
    "# 7\n",
    "sns.boxplot(data=stocks, x=\"weekday\", y=\"difference\", hue=\"name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
