{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Tutorial 03 â€“ Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Today, we will be solving 2 classic machine learning tasks:\n",
    "* classification - predicting a class from predefined set\n",
    "* regression - predicting a value in a continuous range\n",
    "\n",
    "And we will build our a machine learning pipeline in scikit-learn.\n",
    "\n",
    "Real-world datasets are not \"clean\" - they contain features that have to be converted to other types, empty values (NaN), useless or misleading features, etc.\n",
    "\n",
    "To deal with the imperfections in the dataset, we have to write some code that does the transforms. Pipelines allow the code to be reused on multiple datasets and easily swap machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We will work with a real dataset that contains info about accidents in Brno in the year 2018. The source is [here](https://data.gov.cz/datov%C3%A1-sada?iri=https%3A%2F%2Fdata.gov.cz%2Fzdroj%2Fdatov%C3%A9-sady%2Fhttps---kod.brno.cz-api-action-package_show-id-dopravni-nehody)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    accidents = pd.read_csv(\n",
    "        \"https://www.fi.muni.cz/~xcechak1/IB031/datasets/accidents-brno.csv\",\n",
    "        parse_dates=[\"Date\"],\n",
    "    )\n",
    "    accidents[\"WeekDay\"] = accidents.Date.dt.weekday\n",
    "    accidents[\"Month\"] = accidents.Date.dt.month\n",
    "    accidents[\"Day\"] = accidents.Date.dt.day\n",
    "    accidents[\"TotalHarmed\"] = (\n",
    "        accidents[\"DeathToll\"] + accidents[\"HeavyInjuries\"] + accidents[\"LightInjuries\"]\n",
    "    )\n",
    "    return accidents\n",
    "\n",
    "\n",
    "accidents = load_dataset()\n",
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "There is a total of 22 columns in the dataset, but 10 of them are of type `object`! Most of machine learning algorithms work with numerical or categorical data, but not with `object` columns. We will solve this problem by changing them to the `categorical` type.\n",
    "A `categorical` columns takes on a fixed number of possible values (categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 1</b></div>\n",
    "\n",
    "Convert all columns of `object` type to categorical type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols = accidents.select_dtypes(\"object\").columns\n",
    "accidents[object_cols] = accidents[object_cols].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "OK, now check if the columns now have the type `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "All good. Now, let's stop before exploring the dataset more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Train/Test Split\n",
    "\n",
    "When we train a model (this lecture, the model will be a decision tree), we want it to generalize well to unseen data, so it can predict something more than just labels from our training set. How to achieve that? We have to avoid two major issues in machine learning - *overfitting* and *underfitting*.\n",
    "\n",
    "To even know if we are under/overfitting, we need to know how the model acts on unseen data. So we put aside a portion of our data (for example, 20%) and train the model on the rest. Then, we evaluate the model using metrics on the unseen data and see if they are as good as on the training set.\n",
    "\n",
    "We have to do the split before getting statistics on the dataset - our brains are very good at pattern recognition and overfitting, and we could get a biased view on the underlying data distribution. Therefore, always do the train-test split before exploration analysis.\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Intuition for underfitting / overfitting\n",
    "If you want to get some more intuition about overfitting and capacity of a model, you can read this [article](https://towardsdatascience.com/overfitting-vs-underfitting-a-complete-example-d05dd7e19765) with a nice explanation.\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set_orig, test_set_orig = train_test_split(\n",
    "    accidents, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Length of train set: {len(train_set_orig)}\")\n",
    "print(f\"Length of test set:  {len(test_set_orig)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now, we need to extract the column with value we want to predict. In the case of the `accidents` dataset, we will try to predict the value of the damage caused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 2</b></div>\n",
    "\n",
    "Create two new variables `train_set` and `train_labels` with data from `train_set_orig`. `train_set` will contain all columns except **Damage** that we want to predict and `train_labels` will contain only single column **Damage**. Do the same for `test_set_orig`, `test_set`, and `test_labels`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(df, column=\"Damage\"):\n",
    "    labels = df[column]\n",
    "    return df.drop(columns=[column]), labels\n",
    "\n",
    "\n",
    "train_set, train_labels = get_labels(train_set_orig)\n",
    "test_set, test_labels = get_labels(test_set_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We are now ready to do exploratory analysis without getting bias on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()  # make plots prettier\n",
    "\n",
    "sns.countplot(data=train_set, x=\"Month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.plot(\n",
    "    kind=\"scatter\",\n",
    "    x=\"X\",\n",
    "    y=\"Y\",\n",
    "    alpha=0.3,\n",
    "    s=train_labels / 5000,\n",
    "    label=\"Damage\",\n",
    "    figsize=(10, 7),\n",
    "    c=\"TotalHarmed\",\n",
    "    cmap=plt.get_cmap(\"jet\"),\n",
    "    colorbar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: here you can do your own analysis on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We are ready to work with the dataset. But, what if we want to do some preprocessing on the data - e.g., normalization? We would have to use the same preprocessing on both the train and test set and you have to do all your transformations twice and keep their order.\n",
    "\n",
    "Here come [pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) for the rescue! They allow you to write transforms once and then easily apply them to the test set. Even more, pipelines have methods for evaluating machine learning models and can be used with any model supported by `scikit-learn`.\n",
    "\n",
    "#### Some useful pipeline methods\n",
    "* `fit` - calculates parameters needed for transform\n",
    "* `transform` - actually does the transform based on the calculated parameters\n",
    "* `predict` - return predictions of the dataset (should be close to `train_labels` for `train_set`)\n",
    "* `score` - calculate prediction score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We will create the pipeline for numerical features. Usual transformations include [imputation](https://scikit-learn.org/stable/modules/impute.html#impute) of missing values (NaN) and [standardization](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling), which scales every feature to zero mean $\\mu = 0$ and unit variance $\\sigma^2 = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline(\n",
    "    [(\"imputer\", SimpleImputer(strategy=\"median\")), (\"std_scaler\", StandardScaler())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To apply the `num_pipeline` on numerical features only, we have to use the [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_features = train_set.select_dtypes(\"number\").columns\n",
    "pipeline = ColumnTransformer([(\"num\", num_pipeline, num_features),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_set)\n",
    "num_features_transformed = pipeline.transform(train_set)\n",
    "\n",
    "print(f\"Mean: {num_features_transformed.mean():.2f}\")\n",
    "print(f\"Standard deviation: {num_features_transformed.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We can also transform the categorical features using a pipeline. The standard operation for categorical variables is [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) - we encode each category into a new binary column. Each column then indicates the presence or absence of the given category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 3</b></div>\n",
    "\n",
    "Create new pipeline for categorical variables, which will be composed of imputer and one-hot encoder. Then create a new pipeline which transforms both the numerical and the category variables using ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_features = train_set.select_dtypes(\"category\").columns\n",
    "cat_pipeline = Pipeline(\n",
    "    [(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"onehot\", OneHotEncoder())]\n",
    ")\n",
    "\n",
    "pipeline = ColumnTransformer(\n",
    "    [(\"num\", num_pipeline, num_features), (\"cat\", cat_pipeline, cat_features)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_transformed = pipeline.fit_transform(train_set)\n",
    "train_set_transformed.shape  # should be (6127, 80) if the exercise was done correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Decision trees\n",
    "\n",
    "Now, we can use a machine learning model to learn how to predict the damage caused by an accident. We will use [decision trees](https://scikit-learn.org/stable/modules/tree.html), which can be used for both regression and classification tasks.\n",
    "\n",
    "The algorithm used in `scikit-learn` is named `CART` and it is very similar to the `C4.5` decision tree algorithm used in lecture slides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "def print_score(y_true, y_pred):\n",
    "    print(\"Predictions:\", list(y_true[:10]), \"...\")\n",
    "    print(\"Labels:     \", list(y_pred[:10]), \"...\")\n",
    "    print(\n",
    "        f\"RMSE: {rmse(y_true, y_pred):.3f}\"\n",
    "    )  # calculate root mean square error (RMSE) of the regressor\n",
    "\n",
    "\n",
    "reg_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"transform\", pipeline),\n",
    "        (\"reg\", DecisionTreeRegressor(criterion=\"mse\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "reg_pipeline.fit(train_set, train_labels)  # fit the training set\n",
    "train_preds = reg_pipeline.predict(train_set)  # predict the labels based on train data\n",
    "print_score(train_labels, train_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We trained a regressor that has a Root Mean Squared Error of ~2000 CZK on the training set for the damage caused. That should be pretty good, right? Well, let's try on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = reg_pipeline.predict(test_set)\n",
    "print_score(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Not so good results anymore. The tree *overfit* on the training data. We can use multiple methods to reduce overfitting - pruning, feature selection, model capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Exercise 4</b></div>\n",
    "\n",
    "Try to train a `DecisionTreeRegressor` that has similar RMSE on both train and test set and lower than the previous test RMSE. Use some combination of parameters that minimizes the train and test RMSE. Try to get a test RMSE at least lower than 63000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"transform\", pipeline),\n",
    "        (\n",
    "            \"reg\",\n",
    "            DecisionTreeRegressor(\n",
    "                criterion=\"mse\",\n",
    "                splitter=\"best\",\n",
    "                max_depth=6,\n",
    "                max_features=10,\n",
    "                min_samples_split=30,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "reg_pipeline.fit(train_set, train_labels)\n",
    "\n",
    "train_preds = reg_pipeline.predict(train_set)\n",
    "test_preds = reg_pipeline.predict(test_set)\n",
    "\n",
    "print(rmse(train_preds, train_labels))\n",
    "print(rmse(test_preds, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Classification tree\n",
    "\n",
    "Classification trees are similar to regression trees, except they predict value from a fixed domain instead of a continuous value. We will use the accidents dataset once more to predict causes of accidents from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, label_column=\"CausedBy\"):\n",
    "    labels = dataset[label_column]\n",
    "    data = dataset.drop(\n",
    "        columns=[\"ID\", \"Type\", \"MainCause\", label_column]\n",
    "    )  # drop columns which are very related to label\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "train_set_clf, train_labels_clf = prepare_dataset(train_set)\n",
    "test_set_clf, test_labels_clf = prepare_dataset(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<div class=\"alert alert-block alert-danger\"><b>Exercise 5</b></div>\n",
    "\n",
    "Now try to create a classification pipeline on your own. Try to use both numerical and categorical columns, use standard preprocessing and [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). You can use only some features or do more preprocessing (you can try PCA).\n",
    "\n",
    "You are predicting the cause of the accident from other features. Do not overfit the training set and try to get an accuracy of 0.9. You can use [pipeline.score](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline.score) to get score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "num_features = train_set_clf.select_dtypes(\"number\").columns\n",
    "cat_features = train_set_clf.select_dtypes(\"category\").columns\n",
    "\n",
    "clf_pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"transform\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    # (\"num\", num_pipeline, num_features),\n",
    "                    (\"cat\", cat_pipeline, cat_features),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"clf\",\n",
    "            DecisionTreeClassifier(criterion=\"entropy\", max_depth=6, random_state=42),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pipeline.fit(train_set_clf, train_labels_clf)\n",
    "\n",
    "print(f\"Train accuracy: {clf_pipeline.score(train_set_clf, train_labels_clf):.4f}\")\n",
    "print(f\"Test accuracy : {clf_pipeline.score(test_set_clf, test_labels_clf):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification tasks, accuracy is one of available metrics for quantifying the quality of predictions. But, it is not the only one. To see how our model predicts class by class, we can plot a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "sns.reset_orig()\n",
    "plot_confusion_matrix(clf_pipeline, test_set_clf, test_labels_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We can see the class imbalance in target variable here - on average, the accident is caused by the car driver (1200 samples). We can balance the class imbalance in confusion matrix by normalizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf_pipeline, test_set_clf, test_labels_clf, normalize=\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "For explaining the concept of the following metrics, imagine that for each label there are two classes - *positive* and *negative*. Positive means the sample is from that class, negative means it is from some other. It is quite similar to one-hot encoding.\n",
    "\n",
    "* **True Positives (TP)** - sample is from positive class and predicted as positive\n",
    "* **True Negatives (TN)** - sample is from negative class and predicted as negative\n",
    "* **False Positives (FP)** - sample is from negative class and predicted as positive\n",
    "* **False Negatives (FN)** - sample is from positive class and predicted as negative\n",
    "\n",
    "When dealing with some machine learning problems, we want some of these metrics to be high and some do not matter that much - for example, when predicting a disease, the number of False Negatives should be as low as possible, even if there are some False Positives.\n",
    "\n",
    "**Sensitivity** (true positive rate, recall) is percentage of correctly identified positives to all positives.  \n",
    "**Specificity** (true negative rate) is percentage of correctly identified negatives to all negatives.  \n",
    "**$F_1$-score** is a combination of precision and recall and is very often used when evaluating a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "y_true = test_labels_clf\n",
    "y_pred = clf_pipeline.predict(test_set_clf)\n",
    "\n",
    "print(\"Precision = TP / (TP + FP)\")\n",
    "print(precision_score(y_true, y_pred, average=\"micro\"))  # calculate total TP, FN, FP\n",
    "print(\n",
    "    precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    ")  # calculate metrics for each class individually with same weight\n",
    "\n",
    "print(\"\\nRecall = TP / (TP + FN)\")\n",
    "print(recall_score(y_true, y_pred, average=\"micro\"))\n",
    "print(recall_score(y_true, y_pred, average=\"macro\"))\n",
    "\n",
    "print(\"\\nF1 = 2 * (precision * recall) / (precision + recall)\")\n",
    "print(f1_score(y_true, y_pred, average=\"micro\"))\n",
    "print(f1_score(y_true, y_pred, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diktaty Python 3.6",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
